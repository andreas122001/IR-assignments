{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs, string\n",
    "\n",
    "with codecs.open(\"common-english-words.txt\", \"r\", \"utf-8\") as f:\n",
    "    common_words = f.read().split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "#### 1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intelligent behavior people product mind but mind itself more human brain does'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and clean the text\n",
    "text = \"Intelligent behavior in people is a product of the mind. But the mind itself is more like what the human brain does.\"\n",
    "def clean(text):\n",
    "    # To lower case. Has to be done before stopwords are removed otherwise but is not removed\n",
    "    text = text.lower()\n",
    "    # Remove stop words\n",
    "    text = \" \".join(list(filter(lambda x: x not in common_words, text.split(\" \"))))\n",
    "    # Remove punctutation\n",
    "    text = \"\".join(list(filter(lambda x: x not in string.punctuation+\"\\n\\r\\t\\0\", text)))\n",
    "    return text\n",
    "text = clean(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mind': (0, 2),\n",
       " 'more': (0, 1),\n",
       " 'human': (0, 1),\n",
       " 'brain': (0, 1),\n",
       " 'intelligent': (0, 1),\n",
       " 'itself': (0, 1),\n",
       " 'people': (0, 1),\n",
       " 'behavior': (0, 1),\n",
       " 'does': (0, 1),\n",
       " 'product': (0, 1),\n",
       " 'but': (0, 1)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create inverted index (for one document, simple)\n",
    "vocab = dict([(key, (0, text.count(key))) for key in set(text.split(\" \"))])\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mind': {0: 2},\n",
       " 'more': {0: 1},\n",
       " 'human': {0: 1},\n",
       " 'brain': {0: 1},\n",
       " 'intelligent': {0: 1},\n",
       " 'itself': {0: 1},\n",
       " 'people': {0: 1},\n",
       " 'behavior': {0: 1},\n",
       " 'does': {0: 1},\n",
       " 'product': {0: 1},\n",
       " 'but': {0: 1}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a (normal) inverted index\n",
    "# For one document this is just a frequency list\n",
    "def gen_idx(corpus):\n",
    "    # Initiate the index as a dict('term', dict('doc', num_occ))\n",
    "    idx_list = dict([(key, {}) for key in set(\" \".join(corpus).split(\" \"))])\n",
    "    for doc_idx, doc in enumerate(corpus):\n",
    "        # Increment number of occurrences for each occurrence\n",
    "        for term in doc.split(\" \"):\n",
    "            if doc_idx not in idx_list[term].keys():\n",
    "                idx_list[term][doc_idx] = 0\n",
    "            idx_list[term][doc_idx] += 1\n",
    "    return idx_list\n",
    "gen_idx([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocks:\n",
      "0 ['intelligent', 'behavior', 'people']\n",
      "1 ['product', 'mind', 'but']\n",
      "2 ['mind', 'itself', 'more']\n",
      "3 ['human', 'brain', 'does']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mind': {0: [1, 2]},\n",
       " 'more': {0: [2]},\n",
       " 'human': {0: [3]},\n",
       " 'brain': {0: [3]},\n",
       " 'intelligent': {0: [0]},\n",
       " 'itself': {0: [2]},\n",
       " 'people': {0: [0]},\n",
       " 'behavior': {0: [0]},\n",
       " 'does': {0: [3]},\n",
       " 'product': {0: [1]},\n",
       " 'but': {0: [1]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def blockify(corpus, block_size=3):\n",
    "        corpus = [[doc.split(\" \")[block_size*i:block_size*i+block_size] for i in range(len(doc.split(\" \"))//block_size+1)] for doc in corpus] # Please don't look at this monstrosity\n",
    "        corpus = [list(filter(lambda x: len(x) > 0, doc)) for doc in corpus]\n",
    "        return corpus\n",
    "\n",
    "def gen_idx_block(corpus, block_size=3):\n",
    "    # Initiate the index as a dict('term', dict('doc', [block_ids]))\n",
    "    idx_list = dict([(key, {}) for key in set(\" \".join(corpus).split(\" \"))])\n",
    "    corpus_blocks = blockify(corpus, block_size)\n",
    "    for doc_idx, doc in enumerate(corpus, 0):\n",
    "        # Generate blocks\n",
    "        blocks = corpus_blocks[doc_idx]\n",
    "        corpus_blocks.append(blocks)\n",
    "        # For each distinct term in the document\n",
    "        for term in set(doc.split(\" \")):\n",
    "            if doc_idx not in idx_list[term].keys():\n",
    "                idx_list[term][doc_idx] = []\n",
    "            # Find occurrences and add block to block list:\n",
    "            for block_idx, block in enumerate(blocks):\n",
    "                if term in block:\n",
    "                    idx_list[term][doc_idx].append(block_idx)\n",
    "    return idx_list, corpus_blocks\n",
    "\n",
    "# 'word': {doc_id: [block_indices]}\n",
    "# Print the results:\n",
    "print(\"Blocks:\")\n",
    "idx, blocks = gen_idx_block([text], block_size=3)\n",
    "for bid, block in enumerate(blocks[0]):\n",
    "    print(bid,block)\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c) Partial Vocabulary Suffix Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1d) Indexing a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['although know much more human brain even',\n",
       " 'ten years ago thinking engages remains pretty much total',\n",
       " 'mystery it big jigsaw puzzle see many',\n",
       " 'pieces put together there much',\n",
       " 'understand all']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the corpus and clean it\n",
    "corpus = [\n",
    "    \"Although we know much more about the human brain than we did even\",\n",
    "    \"ten years ago, the thinking it engages in remains pretty much a total\",\n",
    "    \"mystery. It is like a big jigsaw puzzle where we can see many of the\",\n",
    "    \"pieces, but cannot yet put them together. There is so much about us\",\n",
    "    \"that we do not understand at all.\",\n",
    "]\n",
    "corpus = [clean(text) for text in corpus]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'many': {2: 1},\n",
       " 'it': {2: 1},\n",
       " 'jigsaw': {2: 1},\n",
       " 'there': {3: 1},\n",
       " 'human': {0: 1},\n",
       " 'remains': {1: 1},\n",
       " 'see': {2: 1},\n",
       " 'although': {0: 1},\n",
       " 'even': {0: 1},\n",
       " 'understand': {4: 1},\n",
       " 'years': {1: 1},\n",
       " 'brain': {0: 1},\n",
       " 'total': {1: 1},\n",
       " 'ten': {1: 1},\n",
       " 'ago': {1: 1},\n",
       " 'pieces': {3: 1},\n",
       " 'puzzle': {2: 1},\n",
       " 'mystery': {2: 1},\n",
       " 'engages': {1: 1},\n",
       " 'more': {0: 1},\n",
       " 'pretty': {1: 1},\n",
       " 'big': {2: 1},\n",
       " 'thinking': {1: 1},\n",
       " 'all': {4: 1},\n",
       " 'know': {0: 1},\n",
       " 'together': {3: 1},\n",
       " 'much': {0: 1, 1: 1, 3: 1},\n",
       " 'put': {3: 1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the inverted index for the corpus \n",
    "# Note: Document ID is one lower than in the assignment text for simplicity\n",
    "index = gen_idx(corpus)\n",
    "index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
